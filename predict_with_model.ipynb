{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d95ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to your dataset (Excel file): D:\\Car Wallpaper\\Genotoxicity\\Train_&_Test_set\\232 external set\\232 Smiles Test Set.xlsx\n",
      "Accuracy: 0.9612068965517241\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from mordred import Calculator, descriptors\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to calculate RDKit descriptors\n",
    "def calculate_rdkit_descriptors(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    rdkit_descriptors = {\n",
    "        'MinEStateIndex': Descriptors.MinEStateIndex(mol),\n",
    "        'qed': Descriptors.qed(mol),\n",
    "        'MaxAbsPartialCharge': Descriptors.MaxAbsPartialCharge(mol),\n",
    "        'MinAbsPartialCharge': Descriptors.MinAbsPartialCharge(mol),\n",
    "        'BCUT2D_MWHI': Descriptors.BCUT2D_MWHI(mol),\n",
    "        'BCUT2D_MWLOW': Descriptors.BCUT2D_MWLOW(mol),\n",
    "        'BCUT2D_MRHI': Descriptors.BCUT2D_MRHI(mol),\n",
    "        'BCUT2D_MRLOW': Descriptors.BCUT2D_MRLOW(mol),\n",
    "        'AvgIpc': Descriptors.AvgIpc(mol),\n",
    "        'BalabanJ': Descriptors.BalabanJ(mol),\n",
    "        'VSA_EState5': Descriptors.VSA_EState5(mol)\n",
    "    }\n",
    "    return pd.DataFrame([rdkit_descriptors])\n",
    "\n",
    "# Function to calculate Mordred descriptors\n",
    "def calculate_mordred_descriptors(smiles):\n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    mordred_descriptors = calc(mol).asdict()\n",
    "\n",
    "    # Select relevant Mordred descriptors\n",
    "    selected_descriptors = {\n",
    "        'ATSC2pe': mordred_descriptors['ATSC2pe'],\n",
    "        'AATSC1c': mordred_descriptors['AATSC1c'],\n",
    "        'MATS2pe': mordred_descriptors['MATS2pe'],\n",
    "        'BCUTdv-1h': mordred_descriptors['BCUTdv-1h'],\n",
    "        'BCUTs-1h': mordred_descriptors['BCUTs-1h'],\n",
    "        'BCUTs-1l': mordred_descriptors['BCUTs-1l'],\n",
    "        'BCUTse-1h': mordred_descriptors['BCUTse-1h'],\n",
    "        'BCUTse-1l': mordred_descriptors['BCUTse-1l'],\n",
    "        'BCUTi-1h': mordred_descriptors['BCUTi-1h'],\n",
    "        'BCUTi-1l': mordred_descriptors['BCUTi-1l'],\n",
    "        'RPCG': mordred_descriptors['RPCG'],\n",
    "        'SpMAD_Dt': mordred_descriptors['SpMAD_Dt']\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame([selected_descriptors])\n",
    "\n",
    "# Function to check if the molecule is connected\n",
    "def is_connected(mol):\n",
    "    visited = set()  \n",
    "    stack = [mol.GetAtoms()[0].GetIdx()]\n",
    "\n",
    "    while stack:\n",
    "        idx = stack.pop()\n",
    "        if idx in visited:\n",
    "            continue\n",
    "        visited.add(idx)\n",
    "        for neighbor in mol.GetAtomWithIdx(idx).GetNeighbors():\n",
    "            stack.append(neighbor.GetIdx())\n",
    "\n",
    "    return len(visited) == mol.GetNumAtoms()\n",
    "\n",
    "# Function to calculate combined descriptors\n",
    "def calculate_descriptors(smiles):\n",
    "    rdkit_df = calculate_rdkit_descriptors(smiles)\n",
    "    mordred_df = calculate_mordred_descriptors(smiles)\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None or not is_connected(mol):\n",
    "        return None\n",
    "    \n",
    "    if rdkit_df is None or mordred_df is None:\n",
    "        return None\n",
    "    \n",
    "    combined_descriptors = pd.concat([rdkit_df, mordred_df], axis=1)\n",
    "\n",
    "    expected_columns = ['MinEStateIndex', 'qed', 'MaxAbsPartialCharge', 'MinAbsPartialCharge', \n",
    "                        'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_MRHI', 'BCUT2D_MRLOW', \n",
    "                        'AvgIpc', 'BalabanJ', 'VSA_EState5', 'ATSC2pe', 'AATSC1c', \n",
    "                        'MATS2pe', 'BCUTdv-1h', 'BCUTs-1h', 'BCUTs-1l', 'BCUTse-1h', \n",
    "                        'BCUTse-1l', 'BCUTi-1h', 'BCUTi-1l', 'RPCG', 'SpMAD_Dt']\n",
    "    \n",
    "    for col in expected_columns:\n",
    "        if col not in combined_descriptors.columns:\n",
    "            combined_descriptors[col] = 0 \n",
    "\n",
    "    combined_descriptors = combined_descriptors[expected_columns]\n",
    "\n",
    "    return combined_descriptors\n",
    "\n",
    "# Load model function\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load the trained model from the specified path.\"\"\"\n",
    "    with open(model_path, 'rb') as f:\n",
    "        return pickle.load(f) \n",
    "\n",
    "# Load data function\n",
    "def load_data(data_path):\n",
    "    \"\"\"Load and preprocess the dataset.\"\"\"\n",
    "    data = pd.read_excel(data_path)\n",
    "    data = data.dropna()\n",
    "    data = data.drop(columns=['Smiles'])  # Drop the 'Smiles' column\n",
    "    X_new = data.drop(columns=['Labels'])  # Features\n",
    "    y_new_true = data['Labels']  # True labels\n",
    "    return X_new, y_new_true\n",
    "\n",
    "# Evaluate model function\n",
    "def evaluate_model(model, X_new, y_new_true):\n",
    "    \"\"\"Evaluate the model on new data and return accuracy.\"\"\"\n",
    "    y_new_pred = model.predict(X_new)\n",
    "    accuracy = accuracy_score(y_new_true, y_new_pred)\n",
    "    return accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = 'model.pkl'\n",
    "    data_path = input(\"Enter the path to your dataset (Excel file): \")\n",
    "\n",
    "    if os.path.exists(model_path) and os.path.exists(data_path):\n",
    "        loaded_model = load_model(model_path)\n",
    "        X_new, y_new_true = load_data(data_path)\n",
    "\n",
    "        # Assuming 'Smiles' column exists in the data for descriptor calculation\n",
    "        if 'Smiles' in pd.read_excel(data_path).columns:\n",
    "            descriptors_df = pd.concat([calculate_descriptors(smiles) for smiles in pd.read_excel(data_path)['Smiles']], ignore_index=True)\n",
    "\n",
    "            X_new = pd.concat([X_new, descriptors_df], axis=1)\n",
    "\n",
    "        accuracy = evaluate_model(loaded_model, X_new, y_new_true)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "    else:\n",
    "        print(\"Error: Model or dataset file not found. Please check the paths.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
